{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsk1KpJGcfck9hDSrjzgrF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Import data & create sample with subset of data"],"metadata":{"id":"_53QcgLGSfU-"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FT9mUOC8dlcA","executionInfo":{"status":"ok","timestamp":1742758161717,"user_tz":420,"elapsed":16750,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"33d1b11a-e39f-480a-feda-f416a2c3b1d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["path = '/content/gdrive/MyDrive/Colab Notebooks/cats_vs_dogs_small'"],"metadata":{"id":"g1s8Ah9IoKPt","executionInfo":{"status":"ok","timestamp":1742758163788,"user_tz":420,"elapsed":4,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","import pathlib\n","\n","# Base directory\n","new_base_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/cats_vs_dogs_small/cats_vs_dogs_small\")\n","\n","# Function to create a sample of images\n","def create_sample(source_dir, target_dir, sample_size):\n","    # Ensure the target directory exists\n","    os.makedirs(target_dir, exist_ok=True)\n","\n","    for category in ['cats', 'dogs']:\n","        src_path = os.path.join(source_dir, category)\n","        target_path = os.path.join(target_dir, category)\n","        os.makedirs(target_path, exist_ok=True)\n","\n","        # Get a list of all image files\n","        files = os.listdir(src_path)\n","        random.shuffle(files)\n","\n","        # Select the desired number of files\n","        selected_files = files[:sample_size // 2]  # Divide evenly between cats and dogs\n","\n","        for file in selected_files:\n","            shutil.copy(os.path.join(src_path, file), os.path.join(target_path, file))\n","\n","# Create training, validation, and test samples\n","create_sample(new_base_dir / 'train', '/content/sample/train', 1000)\n","create_sample(new_base_dir / 'validation', '/content/sample/validation', 500)\n","create_sample(new_base_dir / 'test', '/content/sample/test', 500)\n","\n","# Load data using TensorFlow\n","import tensorflow as tf\n","\n","train_data = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample/train', batch_size=32, image_size=(180, 180), label_mode='int'\n",")\n","\n","val_data = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample/validation', batch_size=32, image_size=(180, 180), label_mode='int'\n",")\n","\n","test_data = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample/test', batch_size=32, image_size=(180, 180), label_mode='int'\n",")\n","\n","# Check the data structure\n","print(f\"Train dataset: {len(train_data)} batches\")\n","print(f\"Validation dataset: {len(val_data)} batches\")\n","print(f\"Test dataset: {len(test_data)} batches\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbLZVoF0oXMH","executionInfo":{"status":"ok","timestamp":1742758262158,"user_tz":420,"elapsed":96801,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"56c232f8-2a6d-43c7-b9f4-d3b3856d3e2a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 files belonging to 2 classes.\n","Found 500 files belonging to 2 classes.\n","Found 500 files belonging to 2 classes.\n","Train dataset: 32 batches\n","Validation dataset: 16 batches\n","Test dataset: 16 batches\n"]}]},{"cell_type":"markdown","source":["#Create base model (model1) from scratch"],"metadata":{"id":"faX5DDVISzDc"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","inputs = keras.Input(shape=(180, 180, 3))\n","x = layers.Rescaling(1./255)(inputs)\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model1 = keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"kgI7SCHO4jiP","executionInfo":{"status":"ok","timestamp":1742758272020,"user_tz":420,"elapsed":145,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":578},"id":"uLIjGJ-g4JHD","executionInfo":{"status":"ok","timestamp":1742758277873,"user_tz":420,"elapsed":49,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"b31fff58-826d-46c3-f3ac-66a65c59fcf3"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m590,080\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │          \u001b[38;5;34m12,545\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,545</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m991,041\u001b[0m (3.78 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991,041</span> (3.78 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m991,041\u001b[0m (3.78 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991,041</span> (3.78 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["model1.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"-fQfptYw5ZTX","executionInfo":{"status":"ok","timestamp":1742758279912,"user_tz":420,"elapsed":23,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#Model1 (base model) performance before any steps to prevent overfitting"],"metadata":{"id":"2gMtlwFeS7fD"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Compile model\n","model1.compile(optimizer=\"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_accuracy',   # Metric to monitor\n","    patience=3,           # Number of epochs to wait before stopping\n","    restore_best_weights=True\n",")\n","\n","# Train model and capture history\n","history = model1.fit(\n","    train_data,\n","    validation_data=val_data,\n","    epochs=30,\n","    callbacks=[early_stopping]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5QcBNPz7TEv","executionInfo":{"status":"ok","timestamp":1742759241049,"user_tz":420,"elapsed":958655,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"a3024dbb-f802-41cb-fc9f-23205c654990"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 3s/step - accuracy: 0.5006 - loss: 0.7057 - val_accuracy: 0.6060 - val_loss: 0.6929\n","Epoch 2/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - accuracy: 0.5482 - loss: 0.6981 - val_accuracy: 0.5020 - val_loss: 0.6903\n","Epoch 3/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5415 - loss: 0.6959 - val_accuracy: 0.5000 - val_loss: 0.6895\n","Epoch 4/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.5841 - loss: 0.6849 - val_accuracy: 0.6180 - val_loss: 0.6682\n","Epoch 5/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.6023 - loss: 0.6861 - val_accuracy: 0.5040 - val_loss: 0.7823\n","Epoch 6/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.6218 - loss: 0.6441 - val_accuracy: 0.6020 - val_loss: 0.6867\n","Epoch 7/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.6636 - loss: 0.6268 - val_accuracy: 0.5560 - val_loss: 0.8031\n"]}]},{"cell_type":"code","source":["# Evaluate on test data\n","test_loss, test_acc = model1.evaluate(test_data)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYeYhGGpgxg2","executionInfo":{"status":"ok","timestamp":1742759528603,"user_tz":420,"elapsed":20526,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"03c88486-c501-4b6f-89b6-dcf5cf1fa98a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 827ms/step - accuracy: 0.5886 - loss: 0.6746\n","Test accuracy: 0.6260\n"]}]},{"cell_type":"markdown","source":["#Data augmentation and dropout added to the model"],"metadata":{"id":"uXjFXVlCTIru"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","val_test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_data2 = train_datagen.flow_from_directory(\n","    '/content/sample/train',\n","    target_size=(180, 180),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","val_data2 = val_test_datagen.flow_from_directory(\n","    '/content/sample/validation',\n","    target_size=(180, 180),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","test_data2 = val_test_datagen.flow_from_directory(\n","    '/content/sample/test',\n","    target_size=(180, 180),\n","    batch_size=32,\n","    class_mode='binary'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gybT8kiTZM8","executionInfo":{"status":"ok","timestamp":1742760787880,"user_tz":420,"elapsed":6979,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"8ad9206e-da79-4fa2-c7b1-31a9054465ad"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 images belonging to 2 classes.\n","Found 500 images belonging to 2 classes.\n","Found 500 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n","\n","model2 = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","\n","    layers.Flatten(),\n","    layers.Dropout(0.5),  # Dropout applied here\n","\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),  # Dropout applied here\n","\n","    layers.Dense(1, activation='sigmoid')\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KErOe47ITzi4","executionInfo":{"status":"ok","timestamp":1742760789730,"user_tz":420,"elapsed":178,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"17dd4f82-cea9-46cc-a88f-7dae41844891"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","source":["# Compile model\n","model2.compile(optimizer=\"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_accuracy',   # Metric to monitor\n","    patience=3,           # Number of epochs to wait before stopping\n","    restore_best_weights=True\n",")\n","\n","# Train model and capture history\n","history2 = model2.fit(\n","    train_data2,\n","    validation_data=val_data2,\n","    epochs=30,\n","    callbacks=[early_stopping]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYrl2Rl0UPzj","executionInfo":{"status":"ok","timestamp":1742762576546,"user_tz":420,"elapsed":1784469,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"62b85471-aefc-4419-da84-5cf4e2d1aaaa"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3s/step - accuracy: 0.4807 - loss: 0.8862 - val_accuracy: 0.5160 - val_loss: 0.6922\n","Epoch 2/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3s/step - accuracy: 0.5294 - loss: 0.6947 - val_accuracy: 0.5480 - val_loss: 0.6892\n","Epoch 3/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 0.5329 - loss: 0.6956 - val_accuracy: 0.5800 - val_loss: 0.6868\n","Epoch 4/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.5745 - loss: 0.6882 - val_accuracy: 0.5660 - val_loss: 0.6697\n","Epoch 5/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.5436 - loss: 0.6901 - val_accuracy: 0.6020 - val_loss: 0.6557\n","Epoch 6/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.5770 - loss: 0.6751 - val_accuracy: 0.6320 - val_loss: 0.6448\n","Epoch 7/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.6343 - loss: 0.6576 - val_accuracy: 0.6540 - val_loss: 0.6274\n","Epoch 8/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.6135 - loss: 0.6432 - val_accuracy: 0.6660 - val_loss: 0.6217\n","Epoch 9/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.6260 - loss: 0.6478 - val_accuracy: 0.6720 - val_loss: 0.6015\n","Epoch 10/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3s/step - accuracy: 0.6130 - loss: 0.6381 - val_accuracy: 0.5580 - val_loss: 0.7600\n","Epoch 11/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.6541 - loss: 0.6494 - val_accuracy: 0.6780 - val_loss: 0.5877\n","Epoch 12/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.6401 - loss: 0.6402 - val_accuracy: 0.6820 - val_loss: 0.5950\n","Epoch 13/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.6581 - loss: 0.6287 - val_accuracy: 0.6660 - val_loss: 0.6061\n","Epoch 14/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.6501 - loss: 0.6091 - val_accuracy: 0.6720 - val_loss: 0.5897\n","Epoch 15/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.6894 - loss: 0.6029 - val_accuracy: 0.7120 - val_loss: 0.5642\n","Epoch 16/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.6613 - loss: 0.6142 - val_accuracy: 0.6760 - val_loss: 0.5846\n","Epoch 17/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.6627 - loss: 0.6039 - val_accuracy: 0.6560 - val_loss: 0.6525\n","Epoch 18/30\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.6336 - loss: 0.6400 - val_accuracy: 0.7080 - val_loss: 0.6002\n"]}]},{"cell_type":"code","source":["# Evaluate on test data\n","test_loss, test_acc = model2.evaluate(test_data2)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRXYIKRAbj1H","executionInfo":{"status":"ok","timestamp":1742762826227,"user_tz":420,"elapsed":12091,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"fc5a0f81-ec89-40b3-895f-43c38367bb51"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - accuracy: 0.6511 - loss: 0.6264\n","Test accuracy: 0.6780\n"]}]},{"cell_type":"markdown","source":["#Increase training sample size to 1500 - validation and test data the same\n"],"metadata":{"id":"zqEzyU09gZWv"}},{"cell_type":"code","source":["import random\n","import shutil\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","import os\n","import pathlib\n","\n","# Base directory - Redefine new_base_dir here\n","new_base_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/cats_vs_dogs_small/cats_vs_dogs_small\")\n","\n","\n","def create_sample(source_dir, target_dir, sample_size):\n","    # Ensure the target directory exists\n","    os.makedirs(target_dir, exist_ok=True)\n","\n","    for category in ['cats', 'dogs']:\n","        src_path = os.path.join(source_dir, category)\n","        target_path = os.path.join(target_dir, category)\n","        os.makedirs(target_path, exist_ok=True)\n","\n","        # Get a list of all image files\n","        files = os.listdir(src_path)\n","        random.shuffle(files)\n","\n","        # Select the desired number of files\n","        selected_files = files[:sample_size // 2]  # Divide evenly between cats and dogsimport os\n","\n","        for file in selected_files:\n","            shutil.copy(os.path.join(src_path, file), os.path.join(target_path, file))\n","\n","# Create training sample\n","create_sample(new_base_dir / 'train', '/content/sample2/train', 1500)\n","\n","\n","# Load data using TensorFlow\n","import tensorflow as tf\n","\n","train_data3 = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample2/train', batch_size=32, image_size=(180, 180), label_mode='binary'\n",")\n","\n","val_data2 = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample/validation', batch_size=32, image_size=(180, 180), label_mode='binary'\n",")\n","\n","test_data2 = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample/test', batch_size=32, image_size=(180, 180), label_mode='binary'\n",")\n","\n","# Check the data structure\n","print(f\"Train dataset: {len(train_data3)} batches\")\n","print(f\"Validation dataset: {len(val_data2)} batches\")\n","print(f\"Test dataset: {len(test_data2)} batches\")\n","\n","\n","# Data augmentation to reduce overfitting\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(\"horizontal\"),\n","    tf.keras.layers.RandomRotation(0.2),\n","    tf.keras.layers.RandomZoom(0.2)\n","])\n","\n","# Build the CNN model\n","model3 = tf.keras.Sequential([\n","    data_augmentation,\n","    tf.keras.layers.Rescaling(1./255), # Normalize pixel values\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),  # Dropout to prevent overfitting\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model3.compile(\n","    optimizer=\"rmsprop\",\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Callbacks\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6)\n","model_checkpoint = ModelCheckpoint(filepath='best_model3.h5', monitor='val_accuracy', save_best_only=True)\n","\n","# Train the model\n","history3 = model3.fit(\n","    train_data3,\n","    validation_data=val_data2,\n","    epochs=30,\n","    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",")\n","\n","# Evaluate on test data\n","test_loss, test_acc = model3.evaluate(test_data2)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avnFGmH1hCUI","executionInfo":{"status":"ok","timestamp":1742765575482,"user_tz":420,"elapsed":1947053,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"1f9f177b-1ed1-4b98-9c12-c4d4c5683cdf"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1991 files belonging to 2 classes.\n","Found 500 files belonging to 2 classes.\n","Found 500 files belonging to 2 classes.\n","Train dataset: 63 batches\n","Validation dataset: 16 batches\n","Test dataset: 16 batches\n","Epoch 1/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4786 - loss: 1.2947"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.4788 - loss: 1.2881 - val_accuracy: 0.5000 - val_loss: 0.6978 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5209 - loss: 0.6951"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3s/step - accuracy: 0.5210 - loss: 0.6951 - val_accuracy: 0.5040 - val_loss: 0.6925 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - accuracy: 0.5356 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.8202 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5075 - loss: 0.7084"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - accuracy: 0.5076 - loss: 0.7082 - val_accuracy: 0.5380 - val_loss: 0.6852 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5589 - loss: 0.6835"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.5589 - loss: 0.6835 - val_accuracy: 0.5980 - val_loss: 0.6610 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 3s/step - accuracy: 0.5978 - loss: 0.6668 - val_accuracy: 0.5960 - val_loss: 0.6554 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5813 - loss: 0.6731"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.5815 - loss: 0.6730 - val_accuracy: 0.6600 - val_loss: 0.6089 - learning_rate: 0.0010\n","Epoch 8/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - accuracy: 0.6380 - loss: 0.6397 - val_accuracy: 0.6240 - val_loss: 0.6343 - learning_rate: 0.0010\n","Epoch 9/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - accuracy: 0.6390 - loss: 0.6298 - val_accuracy: 0.6120 - val_loss: 0.6660 - learning_rate: 0.0010\n","Epoch 10/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.6461 - loss: 0.6304 - val_accuracy: 0.5380 - val_loss: 1.1524 - learning_rate: 0.0010\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 676ms/step - accuracy: 0.6823 - loss: 0.6024\n","Test accuracy: 0.6620\n"]}]},{"cell_type":"markdown","source":["#Increase training sample size to 2000 - validation and test data the same\n"],"metadata":{"id":"Nf_itzgyvjx8"}},{"cell_type":"code","source":["import random\n","import shutil\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","\n","def create_sample(source_dir, target_dir, sample_size):\n","    # Ensure the target directory exists\n","    os.makedirs(target_dir, exist_ok=True)\n","\n","    for category in ['cats', 'dogs']:\n","        src_path = os.path.join(source_dir, category)\n","        target_path = os.path.join(target_dir, category)\n","        os.makedirs(target_path, exist_ok=True)\n","\n","        # Get a list of all image files\n","        files = os.listdir(src_path)\n","        random.shuffle(files)\n","\n","        # Select the desired number of files\n","        selected_files = files[:sample_size // 2]  # Divide evenly between cats and dogsimport os\n","\n","        for file in selected_files:\n","            shutil.copy(os.path.join(src_path, file), os.path.join(target_path, file))\n","\n","# Create training, validation, and test samples\n","create_sample(new_base_dir / 'train', '/content/sample3/train', 2000)\n","\n","\n","# Load data using TensorFlow\n","import tensorflow as tf\n","\n","train_data4 = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample3/train', batch_size=32, image_size=(180, 180), label_mode='binary'\n",")\n","\n","val_data2 = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample/validation', batch_size=32, image_size=(180, 180), label_mode='binary'\n",")\n","\n","test_data2 = tf.keras.utils.image_dataset_from_directory(\n","    '/content/sample/test', batch_size=32, image_size=(180, 180), label_mode='binary'\n",")\n","\n","# Check the data structure\n","print(f\"Train dataset: {len(train_data4)} batches\")\n","print(f\"Validation dataset: {len(val_data2)} batches\")\n","print(f\"Test dataset: {len(test_data2)} batches\")\n","\n","\n","# Data augmentation to reduce overfitting\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(\"horizontal\"),\n","    tf.keras.layers.RandomRotation(0.2),\n","    tf.keras.layers.RandomZoom(0.2)\n","])\n","\n","# Build the CNN model\n","model4 = tf.keras.Sequential([\n","    data_augmentation,\n","    tf.keras.layers.Rescaling(1./255), # Normalize pixel values\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),  # Dropout to prevent overfitting\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model4.compile(\n","    optimizer=\"rmsprop\",\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Callbacks\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6)\n","model_checkpoint = ModelCheckpoint(filepath='best_model4.h5', monitor='val_accuracy', save_best_only=True)\n","\n","# Train the model\n","history4 = model4.fit(\n","    train_data4,\n","    validation_data=val_data2,\n","    epochs=30,\n","    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",")\n","\n","# Evaluate on test data\n","test_loss, test_acc = model4.evaluate(test_data2)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKJwgEt2vvFi","executionInfo":{"status":"ok","timestamp":1742768108205,"user_tz":420,"elapsed":2491950,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"87e263ec-8ea6-4704-eac1-cf74fb415230"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 files belonging to 2 classes.\n","Found 500 files belonging to 2 classes.\n","Found 500 files belonging to 2 classes.\n","Train dataset: 63 batches\n","Validation dataset: 16 batches\n","Test dataset: 16 batches\n","Epoch 1/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4812 - loss: 0.9057"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.4814 - loss: 0.9033 - val_accuracy: 0.5000 - val_loss: 0.6942 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5183 - loss: 0.6954"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.5183 - loss: 0.6954 - val_accuracy: 0.6040 - val_loss: 0.6867 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5669 - loss: 0.6894"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.5669 - loss: 0.6894 - val_accuracy: 0.6100 - val_loss: 0.6428 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - accuracy: 0.5943 - loss: 0.6686 - val_accuracy: 0.6020 - val_loss: 0.6496 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6295 - loss: 0.6479"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.6294 - loss: 0.6479 - val_accuracy: 0.6200 - val_loss: 0.6188 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - accuracy: 0.6395 - loss: 0.6353 - val_accuracy: 0.6200 - val_loss: 0.6403 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6683 - loss: 0.6192"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.6682 - loss: 0.6194 - val_accuracy: 0.6520 - val_loss: 0.6068 - learning_rate: 0.0010\n","Epoch 8/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6628 - loss: 0.6079"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.6628 - loss: 0.6080 - val_accuracy: 0.6540 - val_loss: 0.6031 - learning_rate: 0.0010\n","Epoch 9/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6812 - loss: 0.5908"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.6812 - loss: 0.5910 - val_accuracy: 0.6740 - val_loss: 0.5837 - learning_rate: 0.0010\n","Epoch 10/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6838 - loss: 0.5895"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - accuracy: 0.6836 - loss: 0.5898 - val_accuracy: 0.6940 - val_loss: 0.5747 - learning_rate: 0.0010\n","Epoch 11/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 3s/step - accuracy: 0.7032 - loss: 0.5807 - val_accuracy: 0.6820 - val_loss: 0.5802 - learning_rate: 0.0010\n","Epoch 12/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.7074 - loss: 0.5821 - val_accuracy: 0.6780 - val_loss: 0.5886 - learning_rate: 0.0010\n","Epoch 13/30\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.6894 - loss: 0.5739 - val_accuracy: 0.6300 - val_loss: 0.6405 - learning_rate: 0.0010\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 668ms/step - accuracy: 0.6675 - loss: 0.5910\n","Test accuracy: 0.6880\n"]}]},{"cell_type":"markdown","source":["#Add in pretrained network"],"metadata":{"id":"TOP3h8m7vhc1"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","# Load the VGG16 model without the top layer\n","base_model = VGG16(\n","    weights='imagenet',  # Load pretrained weights from ImageNet\n","    include_top=False,   # Remove fully connected layer\n","    input_shape=(180, 180, 3)  # Image size for VGG16\n",")\n","\n","# Freeze the convolutional base to prevent retraining\n","base_model.trainable = False\n","\n","# Create a new model on top of VGG16\n","model5 = models.Sequential([\n","    base_model,\n","    layers.Flatten(),\n","    layers.Dense(180, activation='relu'),\n","    layers.Dropout(0.5),  # Dropout to reduce overfitting\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model5.compile(\n","    optimizer=\"rmsprop\",\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Callbacks to prevent overfitting\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, min_lr=1e-6)\n","model_checkpoint = ModelCheckpoint(filepath='best_vgg16_model5.h5', monitor='val_accuracy', save_best_only=True)\n","\n","# Train the model\n","history5 = model5.fit(\n","    train_data2,\n","    validation_data=val_data2,\n","    epochs=10,  # Train for 10 epochs first\n","    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",")\n","\n","# Evaluate on test data\n","test_loss, test_acc = model5.evaluate(test_data2)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZVm4aXEFgYF","executionInfo":{"status":"ok","timestamp":1742776819316,"user_tz":420,"elapsed":3243565,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"3b9f32e8-98ac-459a-d07c-8a7438785567"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.6010 - loss: 1.7329 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 19s/step - accuracy: 0.6022 - loss: 1.7170 - val_accuracy: 0.8340 - val_loss: 5.9638 - learning_rate: 0.0010\n","Epoch 2/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.7124 - loss: 0.6113 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 19s/step - accuracy: 0.7129 - loss: 0.6104 - val_accuracy: 0.8400 - val_loss: 7.1310 - learning_rate: 0.0010\n","Epoch 3/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.7601 - loss: 0.5158 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 19s/step - accuracy: 0.7600 - loss: 0.5157 - val_accuracy: 0.8500 - val_loss: 8.8246 - learning_rate: 0.0010\n","Epoch 4/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 19s/step - accuracy: 0.7777 - loss: 0.5005 - val_accuracy: 0.8060 - val_loss: 18.9332 - learning_rate: 0.0010\n","Epoch 5/10\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 19s/step - accuracy: 0.8062 - loss: 0.4441 - val_accuracy: 0.8260 - val_loss: 15.9305 - learning_rate: 0.0010\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 12s/step - accuracy: 0.8673 - loss: 6.6291\n","Test accuracy: 0.8500\n"]}]},{"cell_type":"code","source":["# Load the VGG16 model without the top layer\n","base_model = VGG16(\n","    weights='imagenet',  # Load pretrained weights from ImageNet\n","    include_top=False,   # Remove fully connected layer\n","    input_shape=(180, 180, 3)  # Image size for VGG16\n",")\n","\n","# Freeze the convolutional base to prevent retraining\n","base_model.trainable = False\n","\n","# Create a new model on top of VGG16\n","model6 = models.Sequential([\n","    base_model,\n","    layers.Flatten(),\n","    layers.Dense(180, activation='relu'),\n","    layers.Dropout(0.5),  # Dropout to reduce overfitting\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model6.compile(\n","    optimizer=\"rmsprop\",\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Callbacks to prevent overfitting\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, min_lr=1e-6)\n","model_checkpoint = ModelCheckpoint(filepath='best_vgg16_model6.h5', monitor='val_accuracy', save_best_only=True)\n","\n","# Train the model\n","history6 = model6.fit(\n","    train_data3,\n","    validation_data=val_data2,\n","    epochs=10,  # Train for 10 epochs first\n","    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",")\n","\n","# Evaluate on test data\n","test_loss, test_acc = model6.evaluate(test_data2)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cG9-PNPmjCo","executionInfo":{"status":"ok","timestamp":1742780351102,"user_tz":420,"elapsed":3275492,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"eb0eddac-7a35-48a5-da16-5de5a60a12c5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.8114 - loss: 15.1456 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1046s\u001b[0m 17s/step - accuracy: 0.8125 - loss: 14.9938 - val_accuracy: 0.9160 - val_loss: 0.8590 - learning_rate: 0.0010\n","Epoch 2/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1038s\u001b[0m 16s/step - accuracy: 0.9260 - loss: 0.5173 - val_accuracy: 0.9140 - val_loss: 0.6881 - learning_rate: 0.0010\n","Epoch 3/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 16s/step - accuracy: 0.9618 - loss: 0.2748 - val_accuracy: 0.9160 - val_loss: 0.6935 - learning_rate: 0.0010\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 12s/step - accuracy: 0.9250 - loss: 0.7312\n","Test accuracy: 0.9240\n"]}]},{"cell_type":"code","source":["# Load the VGG16 model without the top layer\n","base_model = VGG16(\n","    weights='imagenet',  # Load pretrained weights from ImageNet\n","    include_top=False,   # Remove fully connected layer\n","    input_shape=(180, 180, 3)  # Image size for VGG16\n",")\n","\n","# Freeze the convolutional base to prevent retraining\n","base_model.trainable = False\n","\n","# Create a new model on top of VGG16\n","model7 = models.Sequential([\n","    base_model,\n","    layers.Flatten(),\n","    layers.Dense(180, activation='relu'),\n","    layers.Dropout(0.5),  # Dropout to reduce overfitting\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model7.compile(\n","    optimizer=\"rmsprop\",\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Callbacks to prevent overfitting\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, min_lr=1e-6)\n","model_checkpoint = ModelCheckpoint(filepath='best_vgg16_model7.h5', monitor='val_accuracy', save_best_only=True)\n","\n","# Train the model\n","history7 = model7.fit(\n","    train_data4,\n","    validation_data=val_data2,\n","    epochs=10,  # Train for 10 epochs first\n","    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",")\n","\n","# Evaluate on test data\n","test_loss, test_acc = model7.evaluate(test_data2)\n","print(f\"Test accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5Rbaf_Qzz5N","executionInfo":{"status":"ok","timestamp":1742783862643,"user_tz":420,"elapsed":3329764,"user":{"displayName":"Faith Taylor","userId":"10017585271030386654"}},"outputId":"2bf8804b-7d53-464a-dfd1-c8472b04d521"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.8063 - loss: 20.7833 "]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 16s/step - accuracy: 0.8075 - loss: 20.5870 - val_accuracy: 0.9420 - val_loss: 0.6198 - learning_rate: 0.0010\n","Epoch 2/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1054s\u001b[0m 16s/step - accuracy: 0.9556 - loss: 0.4802 - val_accuracy: 0.9380 - val_loss: 0.5718 - learning_rate: 0.0010\n","Epoch 3/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1035s\u001b[0m 16s/step - accuracy: 0.9687 - loss: 0.3511 - val_accuracy: 0.9260 - val_loss: 0.6661 - learning_rate: 0.0010\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 12s/step - accuracy: 0.9614 - loss: 0.5031\n","Test accuracy: 0.9560\n"]}]}]}